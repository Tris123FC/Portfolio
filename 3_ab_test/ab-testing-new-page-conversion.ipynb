{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3548178,"sourceType":"datasetVersion","datasetId":2133464}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\npaths = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        x = os.path.join(dirname, filename)\n        paths.append(x)\n\ndf = pd.read_csv(paths[1])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-26T16:14:46.713601Z","iopub.execute_input":"2024-09-26T16:14:46.714055Z","iopub.status.idle":"2024-09-26T16:14:47.035535Z","shell.execute_reply.started":"2024-09-26T16:14:46.714019Z","shell.execute_reply":"2024-09-26T16:14:47.034470Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"## **1. Cleaning and Organising Data**","metadata":{}},{"cell_type":"markdown","source":"**<p style=\"font-size: 18px;\">a) Quick Look at the Data</p>**","metadata":{}},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:14:47.037762Z","iopub.execute_input":"2024-09-26T16:14:47.038186Z","iopub.status.idle":"2024-09-26T16:14:47.052492Z","shell.execute_reply.started":"2024-09-26T16:14:47.038148Z","shell.execute_reply":"2024-09-26T16:14:47.051312Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"   user_id timestamp      group landing_page  converted\n0   851104   11:48.6    control     old_page          0\n1   804228   01:45.2    control     old_page          0\n2   661590   55:06.2  treatment     new_page          0\n3   853541   28:03.1  treatment     new_page          0\n4   864975   52:26.2    control     old_page          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>timestamp</th>\n      <th>group</th>\n      <th>landing_page</th>\n      <th>converted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>851104</td>\n      <td>11:48.6</td>\n      <td>control</td>\n      <td>old_page</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>804228</td>\n      <td>01:45.2</td>\n      <td>control</td>\n      <td>old_page</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>661590</td>\n      <td>55:06.2</td>\n      <td>treatment</td>\n      <td>new_page</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>853541</td>\n      <td>28:03.1</td>\n      <td>treatment</td>\n      <td>new_page</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>864975</td>\n      <td>52:26.2</td>\n      <td>control</td>\n      <td>old_page</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\">The data we are exploring was from a website that performed an AB Test on its users to assess the effectives of two landing pages. From the columns we can see that users are already seperated into groups : control and treatement with columns which track the user id, the landing page, and the conversions.</p","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:14:47.054412Z","iopub.execute_input":"2024-09-26T16:14:47.054942Z","iopub.status.idle":"2024-09-26T16:14:47.065139Z","shell.execute_reply.started":"2024-09-26T16:14:47.054901Z","shell.execute_reply":"2024-09-26T16:14:47.063921Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"(294480, 5)"},"metadata":{}}]},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\">We have nearly 300,000 rows of data for the 5 columns.</p>","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:14:47.068216Z","iopub.execute_input":"2024-09-26T16:14:47.068577Z","iopub.status.idle":"2024-09-26T16:14:47.106615Z","shell.execute_reply.started":"2024-09-26T16:14:47.068547Z","shell.execute_reply":"2024-09-26T16:14:47.105101Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"             user_id      converted\ncount  294480.000000  294480.000000\nmean   787973.538896       0.119658\nstd     91210.917091       0.324562\nmin    630000.000000       0.000000\n25%    709031.750000       0.000000\n50%    787932.500000       0.000000\n75%    866911.250000       0.000000\nmax    945999.000000       1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>converted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>294480.000000</td>\n      <td>294480.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>787973.538896</td>\n      <td>0.119658</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>91210.917091</td>\n      <td>0.324562</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>630000.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>709031.750000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>787932.500000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>866911.250000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>945999.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\">The describe method provides summary statistics of the numerical columns. We can see that the user id is considered a numerical column, but we can just not ignore it as it won't affect our analysis. Looking at the summary statistics for the converted column, we can see the range which is between 0 and 1, and a mean value of 0.119. This makes sense as a conversion is noted as a value of 1 and a non conversion is 0.</p>","metadata":{}},{"cell_type":"markdown","source":"**<p style=\"font-size: 18px;\"> Handling Null and Duplicate Values</p>**","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\"> This code iterates over the each column and sums the number of null values.</p>","metadata":{}},{"cell_type":"code","source":"#Check for NA Values - Print list of columns and number of nan values.\ndf_columns_mask = df.isna().any(axis=0)\ncolumns = df.columns[df_columns_mask]\n\nif len(columns) == 0:\n    print(\"No NaN values found in the DataFrame.\")\nelse:\n    for col in columns:\n        print(f\"Column {col} has {df[col].isna().sum()} NaN values\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:14:47.107970Z","iopub.execute_input":"2024-09-26T16:14:47.108317Z","iopub.status.idle":"2024-09-26T16:14:47.215555Z","shell.execute_reply.started":"2024-09-26T16:14:47.108288Z","shell.execute_reply":"2024-09-26T16:14:47.214302Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"No NaN values found in the DataFrame.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\">For this test, we want to analyse the user experience the first time they enter the two landing pages, so we write the code below to make sure there is only one unique instance of each individual user. This code will drop any successive occurence of the previous user ids.</p>","metadata":{}},{"cell_type":"code","source":"# removed duplicate user_id values.\nprint(df.shape)\ndf = df.drop_duplicates(subset= 'user_id', keep= False)\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:14:47.217140Z","iopub.execute_input":"2024-09-26T16:14:47.217484Z","iopub.status.idle":"2024-09-26T16:14:47.257953Z","shell.execute_reply.started":"2024-09-26T16:14:47.217454Z","shell.execute_reply":"2024-09-26T16:14:47.256673Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"(294480, 5)\n(286690, 5)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\">We can see the numbers of rows decreased from 294,480 to 286,690. This means duplicated user ids were succesfully removed.</p>","metadata":{}},{"cell_type":"markdown","source":"**<p style=\"font-size: 18px;\">Rearanging Table by Landing Pages and Groups</p>**","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\">In order to see how the users were split among the different test groups in the AB test experiment, we can group the data according to landing pages and group type.</p>","metadata":{}},{"cell_type":"code","source":"#count observations for each landing page.\ngrouped = df.groupby(['landing_page', 'group']).agg({'landing_page': 'size'})\ngrouped","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:14:47.259361Z","iopub.execute_input":"2024-09-26T16:14:47.259740Z","iopub.status.idle":"2024-09-26T16:14:47.336413Z","shell.execute_reply.started":"2024-09-26T16:14:47.259710Z","shell.execute_reply":"2024-09-26T16:14:47.335323Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"                        landing_page\nlanding_page group                  \nnew_page     treatment        143397\nold_page     control          143293","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>landing_page</th>\n    </tr>\n    <tr>\n      <th>landing_page</th>\n      <th>group</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>new_page</th>\n      <th>treatment</th>\n      <td>143397</td>\n    </tr>\n    <tr>\n      <th>old_page</th>\n      <th>control</th>\n      <td>143293</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\"> We can see that the groups were pretty evenly split.</p>","metadata":{}},{"cell_type":"code","source":"grouped = df.groupby(['landing_page','group']).agg({'converted':'sum'})\ngrouped","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:14:47.338097Z","iopub.execute_input":"2024-09-26T16:14:47.338466Z","iopub.status.idle":"2024-09-26T16:14:47.413550Z","shell.execute_reply.started":"2024-09-26T16:14:47.338436Z","shell.execute_reply":"2024-09-26T16:14:47.412220Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"                        converted\nlanding_page group               \nnew_page     treatment      17025\nold_page     control        17220","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>converted</th>\n    </tr>\n    <tr>\n      <th>landing_page</th>\n      <th>group</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>new_page</th>\n      <th>treatment</th>\n      <td>17025</td>\n    </tr>\n    <tr>\n      <th>old_page</th>\n      <th>control</th>\n      <td>17220</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\">The old page had slightly more conversions. The code below shows the frequencies in percentage format.</p>","metadata":{}},{"cell_type":"code","source":"grouped = df.groupby('landing_page').agg({'landing_page': 'size'}) / len(df) * 100\ngrouped\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:14:47.417060Z","iopub.execute_input":"2024-09-26T16:14:47.417450Z","iopub.status.idle":"2024-09-26T16:14:47.460795Z","shell.execute_reply.started":"2024-09-26T16:14:47.417416Z","shell.execute_reply":"2024-09-26T16:14:47.459614Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"              landing_page\nlanding_page              \nnew_page         50.018138\nold_page         49.981862","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>landing_page</th>\n    </tr>\n    <tr>\n      <th>landing_page</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>new_page</th>\n      <td>50.018138</td>\n    </tr>\n    <tr>\n      <th>old_page</th>\n      <td>49.981862</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\">The percentages reflect the previous count. There was a near 50% split between the two pages.</p>","metadata":{}},{"cell_type":"code","source":"grouped = df.groupby(['group','landing_page']).agg({'converted': 'mean'})\ngrouped","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:14:47.462376Z","iopub.execute_input":"2024-09-26T16:14:47.462828Z","iopub.status.idle":"2024-09-26T16:14:47.542768Z","shell.execute_reply.started":"2024-09-26T16:14:47.462786Z","shell.execute_reply":"2024-09-26T16:14:47.541614Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"                        converted\ngroup     landing_page           \ncontrol   old_page       0.120173\ntreatment new_page       0.118726","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>converted</th>\n    </tr>\n    <tr>\n      <th>group</th>\n      <th>landing_page</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>control</th>\n      <th>old_page</th>\n      <td>0.120173</td>\n    </tr>\n    <tr>\n      <th>treatment</th>\n      <th>new_page</th>\n      <td>0.118726</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\"> By observing the conversion rates, we see that there was only a slight performance difference. The old page had a conversion rate of 12%. In comparison the new page achieved a conversion rate of 11.8%. If this sample data is proven significant,this might suggest more work needs to be done to optimise the website for increased conversion performance.</p>","metadata":{}},{"cell_type":"markdown","source":"## **2. Testing for Significance**","metadata":{}},{"cell_type":"markdown","source":"**<p style=\"font-size: 18px;\">H0: There is no significant difference between the sample mean and population mean.</p>**\n\n<p style=\"font-size: 16px;\">This means any observed difference is due to random sampling variability.</p>\n\n**<p style=\"font-size: 18px;\">H1: There is a significant difference between the sample and population mean.</p>**\n\n<p style=\"font-size: 16px;\">This indicates that any observed difference is not just due to chance, suggesting a true effect or difference exists.</p>","metadata":{}},{"cell_type":"markdown","source":"**<p style=\"font-size: 18px;\">Using Power Analysis to Compare Two Means**</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\">We choose to perform a two sample Z-test because of the large sample size.\nThe z-test helps to test if our current sample mean of is representative of the general userbase.</p>\n\n<p style=\"font-size: 16px;\">According to the Central Limit Theorem, the sampling distribution of the mean approximates a normal distribution for large samples, even if the population distribution is not normal.</p>\n\n<p style=\"font-size: 16px;\">Using a the Power Analysis method, we will be able to find an adequate sample size for the Z-test which ensures that if there is a significant relationship between the two samples, are test will be able to prove it.</p>","metadata":{}},{"cell_type":"markdown","source":"**<p style=\"font-size: 18px;\">What is Power Analysis?</p>**","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\">Power analysis is a statistical technique used to determine the likelihood that a test will detect an effect, assuming that the effect truly exists. It helps researchers decide whether a test is adequate to detect a statistically significant effect in a hypothesis test.</p>\n\n**Parameters required are:**\n\n- **Power (1 - β):** The probability of safely rejecting the null (we choose an 80% confidence interval).\n\n- **Effect size:** Using Cohen's formula we can calculate the effect size knowing that we want a 1% difference in conversion rate.\n- **Sample size:** The number of participants or observations (we do not yet know the sample size).\n\n- **Significance level (α):** The probability of falsely rejecting the null (alpha = 0.05).\n\n<p style=\"font-size: 16px;\">Knowing three of these parameters allow us to determine the other, luckily enough, we know three of them and just need to know the sample size.</p>","metadata":{}},{"cell_type":"code","source":"from statsmodels.stats.proportion import proportions_ztest\nfrom statsmodels.stats.power import NormalIndPower\n\n# We input our parameters ~ the minimum detectable effect we want is 1% conversion increase (p2 - p1).\np1 = 0.13\np2 = 0.12\n#power parameter.\npower = 0.80\n#alpha parameter\nalpha = 0.05","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:14:47.544301Z","iopub.execute_input":"2024-09-26T16:14:47.544751Z","iopub.status.idle":"2024-09-26T16:14:47.552052Z","shell.execute_reply.started":"2024-09-26T16:14:47.544713Z","shell.execute_reply":"2024-09-26T16:14:47.550710Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"from statsmodels.stats.power import NormalIndPower\nfrom statsmodels.stats.proportion import proportions_ztest\n\n# Calculating the effect size with Cohen's formula.\neffect_size = (p1 - p2) / ((p1 * (1 - p1) + p2 * (1 - p2)) / 2) ** 0.5\n# Calculate the required sample size\nanalysis = NormalIndPower()\nsample_size = analysis.solve_power(effect_size=effect_size, power=power, alpha=alpha, ratio=1.0, alternative='two-sided')\nprint(f'Effect size: {effect_size:.2f}')\n\nprint(f'Required sample size per group: {sample_size:.2f}')\n\nprint(f'Required sample size per group: {sample_size:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:14:47.553877Z","iopub.execute_input":"2024-09-26T16:14:47.554329Z","iopub.status.idle":"2024-09-26T16:14:47.578995Z","shell.execute_reply.started":"2024-09-26T16:14:47.554291Z","shell.execute_reply":"2024-09-26T16:14:47.577732Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"Effect size: 0.03\nRequired sample size per group: 17165.46\nRequired sample size per group: 17165.46\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\">Using Cohen's formula we found that our desired effect size is 0.03.</p>\n<p style=\"font-size: 16px;\">Are required sample size is around 17,165.</p>\n<p style=\"font-size: 16px;\">We are now able to perform our Z-Test to test for significance.</p>","metadata":{}},{"cell_type":"code","source":"# Set the random seed for reproducibility.\nnp.random.seed(45)\n\n# Creates a sample of size 17,165 for each group and reset the index to get a new dataframe with our two data samples.\nsample_df = (df.groupby(['group'])\n         .apply(lambda x: x.sample(n=17165, replace=False))\n         .reset_index(drop=True))","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:14:47.580478Z","iopub.execute_input":"2024-09-26T16:14:47.580938Z","iopub.status.idle":"2024-09-26T16:14:47.678544Z","shell.execute_reply.started":"2024-09-26T16:14:47.580886Z","shell.execute_reply":"2024-09-26T16:14:47.677362Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"sample_df","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:14:47.680060Z","iopub.execute_input":"2024-09-26T16:14:47.680506Z","iopub.status.idle":"2024-09-26T16:14:47.695861Z","shell.execute_reply.started":"2024-09-26T16:14:47.680467Z","shell.execute_reply":"2024-09-26T16:14:47.694499Z"},"trusted":true},"execution_count":85,"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"       user_id timestamp      group landing_page  converted\n0       807689   47:50.8    control     old_page          0\n1       817401   00:36.8    control     old_page          1\n2       652424   28:57.7    control     old_page          0\n3       912117   41:07.2    control     old_page          0\n4       671687   03:04.9    control     old_page          0\n...        ...       ...        ...          ...        ...\n34325   724420   47:05.8  treatment     new_page          0\n34326   646390   07:56.9  treatment     new_page          0\n34327   838051   35:19.1  treatment     new_page          0\n34328   702806   07:35.5  treatment     new_page          0\n34329   828432   47:52.8  treatment     new_page          1\n\n[34330 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>timestamp</th>\n      <th>group</th>\n      <th>landing_page</th>\n      <th>converted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>807689</td>\n      <td>47:50.8</td>\n      <td>control</td>\n      <td>old_page</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>817401</td>\n      <td>00:36.8</td>\n      <td>control</td>\n      <td>old_page</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>652424</td>\n      <td>28:57.7</td>\n      <td>control</td>\n      <td>old_page</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>912117</td>\n      <td>41:07.2</td>\n      <td>control</td>\n      <td>old_page</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>671687</td>\n      <td>03:04.9</td>\n      <td>control</td>\n      <td>old_page</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34325</th>\n      <td>724420</td>\n      <td>47:05.8</td>\n      <td>treatment</td>\n      <td>new_page</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34326</th>\n      <td>646390</td>\n      <td>07:56.9</td>\n      <td>treatment</td>\n      <td>new_page</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34327</th>\n      <td>838051</td>\n      <td>35:19.1</td>\n      <td>treatment</td>\n      <td>new_page</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34328</th>\n      <td>702806</td>\n      <td>07:35.5</td>\n      <td>treatment</td>\n      <td>new_page</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34329</th>\n      <td>828432</td>\n      <td>47:52.8</td>\n      <td>treatment</td>\n      <td>new_page</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>34330 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\"> We can see that instead of 300,000 rows, we now have 34,330 rows we can sample test.</p>","metadata":{}},{"cell_type":"code","source":"# Collect the total observations and total converted per group\nsample_df = (sample_df.groupby('group')\n       .agg(total_observations=('user_id', 'size'),\n            total_converted=('converted', 'sum'))\n       .reset_index())","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:14:47.697865Z","iopub.execute_input":"2024-09-26T16:14:47.698378Z","iopub.status.idle":"2024-09-26T16:14:47.718344Z","shell.execute_reply.started":"2024-09-26T16:14:47.698338Z","shell.execute_reply":"2024-09-26T16:14:47.716932Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"# Extract counts\nconv = sample_df['total_converted'].values\nn = sample_df['total_observations'].values\n\n# Conducts Z-Test to compare the mean of the two samples and see if they differ significantly\nz_stat, p_value = proportions_ztest(count=conv, nobs=n)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:21:15.773734Z","iopub.execute_input":"2024-09-26T16:21:15.774529Z","iopub.status.idle":"2024-09-26T16:21:15.780728Z","shell.execute_reply.started":"2024-09-26T16:21:15.774492Z","shell.execute_reply":"2024-09-26T16:21:15.779587Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"print(\"Z-statistic:\", z_stat)\nprint(\"P-value:\", p_value)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:21:22.607417Z","iopub.execute_input":"2024-09-26T16:21:22.607863Z","iopub.status.idle":"2024-09-26T16:21:22.614457Z","shell.execute_reply.started":"2024-09-26T16:21:22.607821Z","shell.execute_reply":"2024-09-26T16:21:22.612923Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"Z-statistic: -0.43399652860477944\nP-value: 0.664290961882086\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\">The P-Value has a value of 0.66, so we can't reject the null hypothesis.</p>\n<p style=\"font-size: 16px;\">This means are findings might be due to random sample variability.</p>","metadata":{}},{"cell_type":"markdown","source":"## **Hypothesis Results**","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size: 16px;\">There is no significant difference between the two landing pages in terms of conversion rates. We should keep the original landing page until further improvements on the new landing page shows significant improvement in terms of conversion rates.</p>","metadata":{}}]}