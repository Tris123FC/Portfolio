{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654a926b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T15:50:02.813343Z",
     "iopub.status.busy": "2024-09-06T15:50:02.812772Z",
     "iopub.status.idle": "2024-09-06T15:50:05.778878Z",
     "shell.execute_reply": "2024-09-06T15:50:05.777245Z"
    },
    "papermill": {
     "duration": 2.987132,
     "end_time": "2024-09-06T15:50:05.781164",
     "exception": true,
     "start_time": "2024-09-06T15:50:02.794032",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmplfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpf\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "# Might require to install yfinance and mplfinance and keras (!pip install ...)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "import mplfinance as mpf\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead6fb0d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The purpose of this analysis is to get an overall sense of tech stock trends. Later we will apply machine learning to try and predict market trends. For the machine learning part, we use Keras. Keras is a high-level neural networks API, written in Python. It's designed to make building deep learning models straightforward and user-friendly, allowing us to focus on creating models rather than thinking about the underlying maths.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47749885",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 1. Importing Up to Date Stock Data Using yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5eb41b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "I chose to look at the four most well known companies in the tech sector. The start date and end date select a 1 year period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f91e1f2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The data will include columns that represents the ups and downs of the stock price: opening price, closing price, highs, lows and adjusted closing price (a measure more representative of the actual closing price) and the volume of stocks traded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e925ddc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T12:47:27.540899Z",
     "iopub.status.busy": "2024-09-06T12:47:27.540269Z",
     "iopub.status.idle": "2024-09-06T12:47:28.476455Z",
     "shell.execute_reply": "2024-09-06T12:47:28.475001Z",
     "shell.execute_reply.started": "2024-09-06T12:47:27.540856Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of tech stocks for analysis\n",
    "tech_list = ['AAPL', 'GOOG', 'MSFT', 'AMZN']\n",
    "company_names = [\"APPLE\", \"GOOGLE\", \"MICROSOFT\", \"AMAZON\"]\n",
    "\n",
    "# Set the start and end times for data retrieval\n",
    "end = datetime.now()\n",
    "start = datetime(end.year - 1, end.month-1, end.day)\n",
    "\n",
    "# Download the data for each stock\n",
    "company_dfs = []\n",
    "\n",
    "for stock, name in zip(tech_list, company_names):\n",
    "    df = yf.download(stock, start=start, end=end)\n",
    "    df['company_name'] = name\n",
    "    company_dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df_all = pd.concat(company_dfs, axis=0)\n",
    "\n",
    "# Display the last 10 rows of the concatenated DataFrame\n",
    "print(df_all.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee38852",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We can observe the data is indexed by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff28189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T12:47:53.517929Z",
     "iopub.status.busy": "2024-09-06T12:47:53.517427Z",
     "iopub.status.idle": "2024-09-06T12:47:53.529881Z",
     "shell.execute_reply": "2024-09-06T12:47:53.528238Z",
     "shell.execute_reply.started": "2024-09-06T12:47:53.517887Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df9f1cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T12:48:08.444235Z",
     "iopub.status.busy": "2024-09-06T12:48:08.442361Z",
     "iopub.status.idle": "2024-09-06T12:48:08.472494Z",
     "shell.execute_reply": "2024-09-06T12:48:08.470228Z",
     "shell.execute_reply.started": "2024-09-06T12:48:08.444122Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571ff22f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "No null values found in the data. Data is mostly composed of float values representing the prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e711def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T12:48:12.296457Z",
     "iopub.status.busy": "2024-09-06T12:48:12.295929Z",
     "iopub.status.idle": "2024-09-06T12:48:12.339631Z",
     "shell.execute_reply": "2024-09-06T12:48:12.337956Z",
     "shell.execute_reply.started": "2024-09-06T12:48:12.296413Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d8b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T12:49:06.337923Z",
     "iopub.status.busy": "2024-09-06T12:49:06.337440Z",
     "iopub.status.idle": "2024-09-06T12:49:06.355035Z",
     "shell.execute_reply": "2024-09-06T12:49:06.353711Z",
     "shell.execute_reply.started": "2024-09-06T12:49:06.337884Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_all\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0f6ac",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The data imported from Yahoo Finance is extremely reliable. A quick overview of the data and a double check of prices proves the validity of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18869b34",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2. Visualising the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b98fd8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2.1 Time Series Chart of the Adjusted Closing Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0385b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T12:49:22.362699Z",
     "iopub.status.busy": "2024-09-06T12:49:22.362201Z",
     "iopub.status.idle": "2024-09-06T12:49:23.046107Z",
     "shell.execute_reply": "2024-09-06T12:49:23.044625Z",
     "shell.execute_reply.started": "2024-09-06T12:49:22.362656Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Loop through each unique company name and plot the adjusted close price\n",
    "for company_name in df['company_name'].unique():\n",
    "    stock_data = df[df['company_name'] == company_name]\n",
    "    plt.plot(stock_data.index, stock_data['Adj Close'], label=company_name)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Adj Close')\n",
    "plt.title('Adjusted Stock Prices')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0889cd9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2.2 Chart Representing the Highs and Lows of the Stock Market in a 4 Month Period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c16ad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Looking at these charts we can see a downward trend between June and July, followed by a period of recovery. Apple was the least affected\n",
    "Articles from Investopedia suggest it is a mix of investor rotation, interest rate speculation about potential interest rate cuts making stocks less attractive, and earning disappointement from underwhelming earning reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ae7e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T12:54:54.516389Z",
     "iopub.status.busy": "2024-09-06T12:54:54.515349Z",
     "iopub.status.idle": "2024-09-06T12:54:54.523635Z",
     "shell.execute_reply": "2024-09-06T12:54:54.522378Z",
     "shell.execute_reply.started": "2024-09-06T12:54:54.516335Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the index needed to be sorted for candle stick chart\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3959fe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T12:54:56.843676Z",
     "iopub.status.busy": "2024-09-06T12:54:56.843187Z",
     "iopub.status.idle": "2024-09-06T12:54:58.344086Z",
     "shell.execute_reply": "2024-09-06T12:54:58.342696Z",
     "shell.execute_reply.started": "2024-09-06T12:54:56.843634Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date = '2024-04-01'\n",
    "end_date = '2024-08-31'\n",
    "\n",
    "# Filter the DataFrame by date range\n",
    "filtered_df = df.loc[start_date:end_date]\n",
    "\n",
    "for company_name in filtered_df['company_name'].unique():\n",
    "    stock_data = filtered_df[filtered_df['company_name'] == company_name]\n",
    "     \n",
    "    # Select the necessary columns for the candlestick chart\n",
    "    stock_data_candlestick = stock_data[['Open', 'High', 'Low', 'Close']]\n",
    "    \n",
    "    # Plot candlestick chart\n",
    "    mpf.plot(stock_data_candlestick, type='candle', style='charles',\n",
    "             title=f'{company_name} Stock Prices',\n",
    "             ylabel='Price',\n",
    "             figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0590a173",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2.3 Moving Average Charts Based on Periods of 10, 20 and 30 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66945e66",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "While there was a decrease in price between June and July, the moving average price Increased. This suggest that despite the decrease in June, prices are still higher on average than past prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b37e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T12:56:05.948681Z",
     "iopub.status.busy": "2024-09-06T12:56:05.948138Z",
     "iopub.status.idle": "2024-09-06T12:56:08.166954Z",
     "shell.execute_reply": "2024-09-06T12:56:08.165540Z",
     "shell.execute_reply.started": "2024-09-06T12:56:05.948635Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ma_day = [10, 20, 50]\n",
    "\n",
    "# Calculated the moving averages for each company\n",
    "for company in company_names:\n",
    "    company_df = df[df[\"company_name\"] == company]\n",
    "    for ma in ma_day:\n",
    "        column_name = f\"MA for {ma} days\"\n",
    "        df.loc[df[\"company_name\"] == company, column_name] = company_df['Adj Close'].rolling(ma).mean()\n",
    "        \n",
    "# Also added a column for daily returns which is the percentage change in price for future visualisation\n",
    "df['Daily Return'] = df.groupby('company_name')['Adj Close'].pct_change()\n",
    "\n",
    "# Created seperate dataframes for each company\n",
    "AAPL = df[df[\"company_name\"] == \"APPLE\"]\n",
    "GOOG = df[df[\"company_name\"] == \"GOOGLE\"]\n",
    "MSFT = df[df[\"company_name\"] == \"MICROSOFT\"]\n",
    "AMZN = df[df[\"company_name\"] == \"AMAZON\"]\n",
    "\n",
    "# Arrange the plots to display 4 charts side by side\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "#APPLE\n",
    "AAPL[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,0])\n",
    "axes[0,0].set_title('APPLE')\n",
    "\n",
    "#GOOGLE\n",
    "GOOG[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,1])\n",
    "axes[0,1].set_title('GOOGLE')\n",
    "\n",
    "#MICROSOFT\n",
    "MSFT[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,0])\n",
    "axes[1,0].set_title('MICROSOFT')\n",
    "\n",
    "#AMAZON\n",
    "AMZN[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,1])\n",
    "axes[1,1].set_title('AMAZON')\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49a5625",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2.4 Charts Representing Daily Returns from Stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cf0ac9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The daily returns show the volatility of stocks in the market. You can quickly see that the percentage daily returns moves around the 0% mark. Amazon and Google have a slightly wider variation range, but changes generally don't go past the 0.1% mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcac3de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T12:56:26.348203Z",
     "iopub.status.busy": "2024-09-06T12:56:26.347719Z",
     "iopub.status.idle": "2024-09-06T12:56:28.698954Z",
     "shell.execute_reply": "2024-09-06T12:56:28.697601Z",
     "shell.execute_reply.started": "2024-09-06T12:56:26.348135Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "AAPL['Daily Return'].plot(ax=axes[0,0], legend=True, linestyle='--', marker='o')\n",
    "axes[0,0].set_title('APPLE')\n",
    "\n",
    "GOOG['Daily Return'].plot(ax=axes[0,1], legend=True, linestyle='--', marker='o')\n",
    "axes[0,1].set_title('GOOGLE')\n",
    "\n",
    "MSFT['Daily Return'].plot(ax=axes[1,0], legend=True, linestyle='--', marker='o')\n",
    "axes[1,0].set_title('MICROSOFT')\n",
    "\n",
    "AMZN['Daily Return'].plot(ax=axes[1,1], legend=True, linestyle='--', marker='o')\n",
    "axes[1,1].set_title('AMAZON')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dfd71f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2.5 Daily Return Distribution Charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbee44a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The Daily Returns tend to centre around a mean of zero, showing characteristics of a nomral distribution. Google and Amazon have a wider range in percentage changes,but the extreme values are rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9a0706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T12:56:46.481602Z",
     "iopub.status.busy": "2024-09-06T12:56:46.481087Z",
     "iopub.status.idle": "2024-09-06T12:56:47.952201Z",
     "shell.execute_reply": "2024-09-06T12:56:47.950591Z",
     "shell.execute_reply.started": "2024-09-06T12:56:46.481559Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "# Loop through the list of companies\n",
    "for i, company_name in enumerate(company_names, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    company_data = df[df[\"company_name\"] == company_name]\n",
    "    company_data['Daily Return'].hist(bins=50)\n",
    "    plt.xlabel('Daily Return')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title(f'{company_name}')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca359de",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2.6 Stock Correlation Between the Four Big Tech Companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c52b3b2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "There are are positive correlations between each stock suggesting stock performance is affected by common factors as stock market speculation, and investor sentiment. Amazon and Google stock have a strong correlation between stocks performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda81d5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T14:02:22.362841Z",
     "iopub.status.busy": "2024-09-06T14:02:22.362336Z",
     "iopub.status.idle": "2024-09-06T14:02:22.566231Z",
     "shell.execute_reply": "2024-09-06T14:02:22.564804Z",
     "shell.execute_reply.started": "2024-09-06T14:02:22.362801Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Created a df of Adjusted Closing Prices for Heat Map Analysis of stock correlations\n",
    "# The cell values represent the daily return or percentage change in closing prices\n",
    "closing_df = yf.download(tech_list, start=start, end=end)['Adj Close']\n",
    "tech_rets = closing_df.pct_change()\n",
    "tech_rets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aba85a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T12:57:24.517592Z",
     "iopub.status.busy": "2024-09-06T12:57:24.517065Z",
     "iopub.status.idle": "2024-09-06T12:57:25.468095Z",
     "shell.execute_reply": "2024-09-06T12:57:25.466829Z",
     "shell.execute_reply.started": "2024-09-06T12:57:24.517547Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.heatmap(tech_rets.corr(), annot=True, cmap='Reds')\n",
    "plt.title('Correlation of stock return')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.heatmap(closing_df.corr(), annot=True, cmap='Reds')\n",
    "plt.title('Correlation of stock closing price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dc7121",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2.7 Analysis of Risk and Expected Return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53552bde",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Overall each Tech stock is relatively low risk with low returns as they are well-established with a good reputation.\n",
    "However when comparing the four we can see that Apple is the best stock to invest in as it is low risk with better expected returns.\n",
    "Google on the otherhand is the the least attractive as in as it has higher risk and low expected returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e31ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T14:07:45.566713Z",
     "iopub.status.busy": "2024-09-06T14:07:45.566235Z",
     "iopub.status.idle": "2024-09-06T14:07:46.228005Z",
     "shell.execute_reply": "2024-09-06T14:07:46.226753Z",
     "shell.execute_reply.started": "2024-09-06T14:07:45.566670Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removes the previous NA values\n",
    "rets = tech_rets.dropna()\n",
    "\n",
    "#define the area of the dots.\n",
    "area = np.pi * 20\n",
    "\n",
    "# Create a scatter plot showing risk against expected return\n",
    "plt.figure(figsize=(10, 8))\n",
    "#the mean of the return values is the expected return, and the standard deviation is the measure of risk.\n",
    "plt.scatter(rets.mean(), rets.std(), s=area)\n",
    "plt.xlabel('Expected return')\n",
    "plt.ylabel('Risk')\n",
    "\n",
    "#Labels the chart\n",
    "for label, x, y in zip(rets.columns, rets.mean(), rets.std()):\n",
    "    plt.annotate(label, xy=(x, y), xytext=(50, 50), textcoords='offset points', ha='right', va='bottom', \n",
    "                 arrowprops=dict(arrowstyle='-', color='blue', connectionstyle='arc3,rad=-0.3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b53af7b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 3. Modelling Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e75a02",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Keras implementation:\n",
    "We use the LSTM (Long Short Term Memory) model, which is effective in predicted values based long term time-series data.\n",
    "This model analyses multidimensional test data in sequences, gradually reducing the complexity until a single regression output is met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefe04ce",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 3.1 Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709dedc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T12:58:27.467203Z",
     "iopub.status.busy": "2024-09-06T12:58:27.465419Z",
     "iopub.status.idle": "2024-09-06T12:58:27.611230Z",
     "shell.execute_reply": "2024-09-06T12:58:27.609895Z",
     "shell.execute_reply.started": "2024-09-06T12:58:27.467114Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# created a larger dataframe for improved testing, I have chosen 10 years of sample data.\n",
    "df2 = yf.download(stock, start= '2014-01-01', end=end)\n",
    "data = df2.filter(['Close'])\n",
    "# Converted the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "# Get the number of rows to train the model on, we use 95% of data.\n",
    "training_data_len = int(np.ceil( len(dataset) * .95 ))\n",
    "#the ceil method in numpy rounds up the value to prevent loss of data due to rounding when spliting the data.\n",
    "training_data_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74048e32",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 3.2 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551b1700",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Standardising the data using MinMaxScaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db12f35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T12:58:38.464961Z",
     "iopub.status.busy": "2024-09-06T12:58:38.464452Z",
     "iopub.status.idle": "2024-09-06T12:58:38.570974Z",
     "shell.execute_reply": "2024-09-06T12:58:38.569619Z",
     "shell.execute_reply.started": "2024-09-06T12:58:38.464915Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#Standardise the data for improved performance\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "#holds the stansformed dataset\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b441b16f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 3.3 Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d20d000",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Training Data Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3e8100",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Mapping previous sequences of data with later data so that the model can learn from previous results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a8773d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T15:24:57.512502Z",
     "iopub.status.busy": "2024-09-06T15:24:57.510597Z",
     "iopub.status.idle": "2024-09-06T15:24:57.536706Z",
     "shell.execute_reply": "2024-09-06T15:24:57.534301Z",
     "shell.execute_reply.started": "2024-09-06T15:24:57.512438Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = scaled_data[0:int(training_data_len), :]\n",
    "# Split the data into x_train and y_train data sets\n",
    "# This is essentialy mapping previous data with later data points in the series, creating a sort of short-term memory for the model.\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "# Create two sets of data, mapping previous data with later data using array indices\n",
    "    x_train.append(train_data[i-60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "    if i<= 61:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()\n",
    "        \n",
    "# Convert the x_train and y_train to the required numpy format\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# The LSTM model requires the data to be in a specific shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ce4dd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Overview of the Process\n",
    "* model = Sequential(): Initialise a sequential model, which is a linear stack of layers.\n",
    "* LSTM(128): Adds an LSTM layer with 128 units. The number of units defines the dimensionality of the output space.\n",
    "* return_sequences=True: This argument ensures that the LSTM layer returns the full sequence of outputs for each input sequence. This is important when stacking multiple LSTM layers, as the next LSTM layer expects a sequence as input.\n",
    "* input_shape=(x_train.shape[1], 1): Specifies the shape of the input data. Here, x_train.shape[1] is the number of time steps (e.g., 60 in your earlier code), and 1 represents the number of features (since you are likely working with a univariate time series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e18e8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T13:00:26.050573Z",
     "iopub.status.busy": "2024-09-06T13:00:26.049944Z",
     "iopub.status.idle": "2024-09-06T13:02:24.849580Z",
     "shell.execute_reply": "2024-09-06T13:02:24.847686Z",
     "shell.execute_reply.started": "2024-09-06T13:00:26.050517Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "# Build the LSTM model\n",
    "#Initialise a sequential model, which is a linear stack of layers\n",
    "model = Sequential()\n",
    "#Add two seperate layers\n",
    "#The second layer only needs the output and not a sequence so return_sequence is set to false\n",
    "model.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "#Adds a Dense (fully connected) layer with 25 neurons\n",
    "#This layer helps the model learn more complex representations of the data after the LSTM layers\n",
    "model.add(Dense(25))\n",
    "#Adds a Dense layer with 1 neuron, which is the output layer\n",
    "#This is a regression problem, so we need the final layer to produce a single output\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# Adam optimizer is often used for its efficiency in training deep networks\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cda7bd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Testing Data Set Up\n",
    "Same process used in setting up the training data but the data we use for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f60e92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T13:03:02.166521Z",
     "iopub.status.busy": "2024-09-06T13:03:02.165453Z",
     "iopub.status.idle": "2024-09-06T13:03:03.310764Z",
     "shell.execute_reply": "2024-09-06T13:03:03.309253Z",
     "shell.execute_reply.started": "2024-09-06T13:03:02.166466Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = scaled_data[training_data_len - 60: , :]\n",
    "# Create the data sets x_test and y_test\n",
    "x_test = []\n",
    "y_test = dataset[training_data_len:, :]\n",
    "for i in range(60, len(test_data)):\n",
    "    x_test.append(test_data[i-60:i, 0])\n",
    "    \n",
    "# Convert the data to a numpy array\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# Reshape the data\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n",
    "\n",
    "# Get the models predicted price values \n",
    "predictions = model.predict(x_test)\n",
    "# Since the data was scaled before training, you need to reverse the scaling to get the actual predicted values. \n",
    "# This step ensures that the predictions are in the same scale as the original data.\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Get the root mean squared error (RMSE)\n",
    "# RMSE is a common metric for regression tasks, measuring the average magnitude of the errors between predicted and actual values.\n",
    "rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eb6f65",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The model as a mean squared error of 4.44. Considering the compared values ranged between 160 and 200 over that period, we can be sastified with the error margin when looking at overall trends. However, this most model cannnot be used to predict the exact price and inform trade decisions as a difference of 4$ determine whether a trade is profitable or loss making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f31e1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 3.4 Visualisation of Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a039fa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The first visulisation shows a wide view of the model predictions based on 10 years of data. We can see thatthe model did quite a good job at fitting the values with its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ef3a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T13:03:30.998491Z",
     "iopub.status.busy": "2024-09-06T13:03:30.997842Z",
     "iopub.status.idle": "2024-09-06T13:03:31.634620Z",
     "shell.execute_reply": "2024-09-06T13:03:31.632836Z",
     "shell.execute_reply.started": "2024-09-06T13:03:30.998432Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = data[:training_data_len]\n",
    "valid = data[training_data_len:]\n",
    "valid['Predictions'] = predictions\n",
    "# Visualize the data\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close', 'Predictions']])\n",
    "plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681a9e6f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Zooming in, we see that there is still a significant margin of error. This model can be used to gain an overall sense of market trends, but it should not be used to predict exact prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2f80b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T15:33:11.715993Z",
     "iopub.status.busy": "2024-09-06T15:33:11.714401Z",
     "iopub.status.idle": "2024-09-06T15:33:12.304556Z",
     "shell.execute_reply": "2024-09-06T15:33:12.302694Z",
     "shell.execute_reply.started": "2024-09-06T15:33:11.715932Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date = '2024-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "# Filter the DataFrame by date range to get a more zoomed in view.\n",
    "filtered_train = train.loc[start_date:end_date]\n",
    "filtered_valid = valid.loc[start_date:end_date]\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "plt.plot(filtered_train['Close'])\n",
    "plt.plot(filtered_valid[['Close', 'Predictions']])\n",
    "plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a982bab3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d2cb3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "From our analysis of some of the biggest tech companies, we found:\n",
    "* June-July market downturn, suggested to be caused by investor rotation, market speculation, and disappointing earnings.\n",
    "* However, Moving average prices have been increasing, suggesting a strong and steady tech sector.\n",
    "* There are positive correlations between each stock because of the similar industry, they are affected by similar market ups and downs.\n",
    "* Using LSTM modeling, we are able to accurately predict the overall trends of the markets.\n",
    "* Further refining, would lead to more accurate price predictions."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4538,
     "sourceId": 7213,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.103501,
   "end_time": "2024-09-06T15:50:06.522056",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-06T15:49:59.418555",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
